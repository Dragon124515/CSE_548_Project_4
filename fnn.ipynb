{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9298e923",
   "metadata": {},
   "source": [
    "# Christian Stonecipher\n",
    "# Project 4: fnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "795d5878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas to import the needed dataset\n",
    "import pandas as pd\n",
    "# Import numpy to perform operations on the dataset\n",
    "import numpy as np\n",
    "\n",
    "# Import sklearn functions to preprocess the dataset\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Import sklearn functions to measure and output model performance\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Import keras to form and train the ML models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d68b721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location and name of the Datasets\n",
    "DatasetPath='Scenario_A/'\n",
    "TrainingData='Training-a1-a3.csv'\n",
    "TestingData='Testing-a2-a4.csv'\n",
    "\n",
    "# Batch Size\n",
    "BatchSize=10\n",
    "# Epohe Size\n",
    "NumEpoch=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b58c3fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 1 0]\n",
      "[0 1 1 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Importing the datasets\n",
    "TrainingDataset = pd.read_csv(DatasetPath+TrainingData, header=None)\n",
    "TestingDataset = pd.read_csv(DatasetPath+TestingData, header=None)\n",
    "\n",
    "# Initial setup of training data\n",
    "Train_X = TrainingDataset.iloc[:, 0:-2].values\n",
    "Train_label_column = TrainingDataset.iloc[:, -2].values\n",
    "\n",
    "Train_y = []\n",
    "for i in range(len(Train_label_column)):\n",
    "    if Train_label_column[i] == 'normal':\n",
    "        Train_y.append(0)\n",
    "    else:\n",
    "        Train_y.append(1)\n",
    "\n",
    "Train_y = np.array(Train_y)\n",
    "\n",
    "# Initial setup of testing data\n",
    "Test_X = TestingDataset.iloc[:, 0:-2].values\n",
    "Test_label_column = TestingDataset.iloc[:, -2].values\n",
    "\n",
    "Test_y = []\n",
    "for i in range(len(Test_label_column)):\n",
    "    if Test_label_column[i] == 'normal':\n",
    "        Test_y.append(0)\n",
    "    else:\n",
    "        Test_y.append(1)\n",
    "\n",
    "Test_y = np.array(Test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "386da32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two datasets to ensure that the one hot encoding outputs the same columns\n",
    "combined = np.concatenate((Train_X,Test_X))\n",
    "num_Train = len(Train_X)\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [('one_hot_encoder', OneHotEncoder(), [1,2,3])],    # The column numbers to be transformed ([1, 2, 3] represents three columns to be transferred)\n",
    "    remainder='passthrough'                             # Leave the rest of the columns untouched\n",
    ")\n",
    "\n",
    "combined = np.array(ct.fit_transform(combined), dtype=float)\n",
    "\n",
    "#Seporate the encoded datasets back out\n",
    "Train_X = combined[:num_Train]\n",
    "Test_X = combined[num_Train:]\n",
    "\n",
    "# Scale the data in the datasets to the range of [0,1]\n",
    "sc = StandardScaler()\n",
    "Train_X = sc.fit_transform(Train_X)  \n",
    "Test_X = sc.fit_transform(Test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77a1826f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-03 13:00:23.057049: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2\n",
      "2022-12-03 13:00:23.087830: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3696000000 Hz\n",
      "2022-12-03 13:00:23.087999: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x23abb30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-12-03 13:00:23.088011: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-12-03 13:00:23.089696: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# Set up the FNN\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = len(Train_X[0])))\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac644173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11333/11333 [==============================] - 39s 3ms/step - loss: 0.0327 - accuracy: 0.9874\n",
      "Epoch 2/10\n",
      "11333/11333 [==============================] - 42s 4ms/step - loss: 0.0124 - accuracy: 0.9952\n",
      "Epoch 3/10\n",
      "11333/11333 [==============================] - 29s 3ms/step - loss: 0.0095 - accuracy: 0.9973\n",
      "Epoch 4/10\n",
      "11333/11333 [==============================] - 24s 2ms/step - loss: 0.0084 - accuracy: 0.9977\n",
      "Epoch 5/10\n",
      "11333/11333 [==============================] - 28s 2ms/step - loss: 0.0080 - accuracy: 0.9978\n",
      "Epoch 6/10\n",
      "11333/11333 [==============================] - 31s 3ms/step - loss: 0.0075 - accuracy: 0.9979\n",
      "Epoch 7/10\n",
      "11333/11333 [==============================] - 29s 3ms/step - loss: 0.0074 - accuracy: 0.9980\n",
      "Epoch 8/10\n",
      "11333/11333 [==============================] - 30s 3ms/step - loss: 0.0070 - accuracy: 0.9980\n",
      "Epoch 9/10\n",
      "11333/11333 [==============================] - 31s 3ms/step - loss: 0.0067 - accuracy: 0.9982\n",
      "Epoch 10/10\n",
      "11333/11333 [==============================] - 31s 3ms/step - loss: 0.0065 - accuracy: 0.9982\n",
      "3542/3542 [==============================] - 9s 3ms/step - loss: 0.0060 - accuracy: 0.9982\n",
      "Print the loss and the accuracy of the model on the dataset\n",
      "Loss [0,1]: 0.0060 Accuracy [0,1]: 0.9982\n"
     ]
    }
   ],
   "source": [
    "# train the keras model\n",
    "classifierHistory = classifier.fit(Train_X, Train_y, batch_size = BatchSize, epochs = NumEpoch, use_multiprocessing=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "09264bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print the Confusion Matrix:\n",
      "[ TN, FP ]\n",
      "[ FN, TP ]=\n",
      "[[8714  997]\n",
      " [2538 2768]]\n",
      "F1 score = \n",
      "0.6102965494432808\n",
      "Accuracy = \n",
      "0.764600119864154\n"
     ]
    }
   ],
   "source": [
    "# Run the model on the testing data\n",
    "y_pred = classifier.predict(Test_X)\n",
    "y_pred = (y_pred > 0.9)   \n",
    "\n",
    "# Determine and output the performance of the model on the testing dataset\n",
    "cm = confusion_matrix(Test_y, y_pred)\n",
    "print('Print the Confusion Matrix:')\n",
    "print('[ TN, FP ]')\n",
    "print('[ FN, TP ]=')\n",
    "print(cm)\n",
    "\n",
    "\n",
    "f1 = f1_score(Test_y, y_pred)\n",
    "print('F1 score = ')\n",
    "print(f1)\n",
    "\n",
    "\n",
    "acc = accuracy_score(Test_y, y_pred)\n",
    "print('Accuracy = ')\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c5655e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa4cfc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
